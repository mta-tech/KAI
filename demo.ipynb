{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection created successfully.\n",
      "{\n",
      "  \"id\": \"a7146dba-ad91-4994-812e-eff9e1d2f111\",\n",
      "  \"alias\": \"service_instances\",\n",
      "  \"dialect\": \"postgresql\",\n",
      "  \"connection_uri\": \"gAAAAABm4GBzhdyQ0G0VfVbTbRiBWnobnD4vzgu6_7m8UBqWwGkTIo4bfnkuvpc1AJyxg0uTqZniYILslkmcJHL2m1TspgNpD9UdZQOEYv8bmy_ww59W6wIwKoRN7z5eB85iX9jToXGevZuqPZ3lR_cKAYXtPq_NZg==\",\n",
      "  \"schemas\": [\n",
      "    \"public\"\n",
      "  ],\n",
      "  \"metadata\": {},\n",
      "  \"created_at\": \"2024-09-10T22:06:27.153462\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "# Define the endpoint for creating a database connection\n",
    "endpoint = \"/api/v1/database-connections\"\n",
    "\n",
    "# Define the payload for the POST request\n",
    "payload = {\n",
    "    \"alias\": \"service_instances\",\n",
    "    \"connection_uri\": \"postgresql://myuser:mypassword@localhost:15432/mydatabase\",\n",
    "    \"schemas\": [\n",
    "        \"public\"\n",
    "    ],\n",
    "    \"metadata\": {}\n",
    "}\n",
    "\n",
    "# Send the POST request to create a database connection\n",
    "response = requests.post(f\"{base_url}{endpoint}\", json=payload)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 201:\n",
    "    print(\"Database connection created successfully.\")\n",
    "    print(json.dumps(response.json(), indent=2))  # Print the response data\n",
    "else:\n",
    "    print(f\"Failed to create database connection. Status Code: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection created successfully.\n",
      "{\n",
      "  \"id\": \"1affbce9-b94b-4e0c-a91d-0f88769d4983\",\n",
      "  \"alias\": \"service_instances\",\n",
      "  \"dialect\": \"postgresql\",\n",
      "  \"connection_uri\": \"gAAAAABm4GFiIVmoyQaOW4M5tBhSnX0u3B28t2yyMFdsD2FubHFrV29eW8yTuXDgY0-3SphMLtqe9ukQ5nZWWnMf2Z9bnbuoV8Vmdt6n-qa591u2dEKEEwWPURrAx-vCAZwy81tpxG1FTbTqbAaV-7TWElUpSLgxPA==\",\n",
      "  \"schemas\": [\n",
      "    \"public\"\n",
      "  ],\n",
      "  \"metadata\": {},\n",
      "  \"created_at\": \"2024-09-10T22:10:26.603773\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Send the POST request to create a database connection\n",
    "response = requests.post(f\"{base_url}{endpoint}\", json=payload)\n",
    "\n",
    "# Check the response status\n",
    "if response.status_code == 201:\n",
    "    print(\"Database connection created successfully.\")\n",
    "    print(json.dumps(response.json(), indent=2))  # Print the response data\n",
    "else:\n",
    "    print(f\"Failed to create database connection. Status Code: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '1affbce9-b94b-4e0c-a91d-0f88769d4983', 'alias': 'service_instances', 'dialect': 'postgresql', 'connection_uri': 'gAAAAABm4GFiIVmoyQaOW4M5tBhSnX0u3B28t2yyMFdsD2FubHFrV29eW8yTuXDgY0-3SphMLtqe9ukQ5nZWWnMf2Z9bnbuoV8Vmdt6n-qa591u2dEKEEwWPURrAx-vCAZwy81tpxG1FTbTqbAaV-7TWElUpSLgxPA==', 'schemas': ['public'], 'metadata': {}, 'created_at': '2024-09-10T22:10:26.603773'}, {'id': 'a7146dba-ad91-4994-812e-eff9e1d2f111', 'alias': 'service_instances', 'dialect': 'postgresql', 'connection_uri': 'gAAAAABm4GBzhdyQ0G0VfVbTbRiBWnobnD4vzgu6_7m8UBqWwGkTIo4bfnkuvpc1AJyxg0uTqZniYILslkmcJHL2m1TspgNpD9UdZQOEYv8bmy_ww59W6wIwKoRN7z5eB85iX9jToXGevZuqPZ3lR_cKAYXtPq_NZg==', 'schemas': ['public'], 'metadata': {}, 'created_at': '2024-09-10T22:06:27.153462'}, {'id': '23e59cd2-be00-4b87-b799-d781070c8a57', 'alias': 'postgresdvd', 'dialect': 'postgresql', 'connection_uri': 'gAAAAABm0CiyWCdSD1clIfSdfzKgE4kh-3-30Wp3frONblMCJrKgVp2tVdq9qqa_fqWuAo6v5NJtkjY7lUh85brQVySvBjzO-Xwgeo3l-4NPghb-yTDO4Tm4mBwXc2qs1mvaMLTNjl0KEiP_uIK7sJzFahvgg731QhbzShdQWjgxVxzezyyEdJ0=', 'schemas': ['public'], 'metadata': {}, 'created_at': '2024-08-29T14:52:17.971425'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('http://localhost:8000/api/v1/database-connections')\n",
    "if response.status_code == 200:\n",
    "    connections = response.json()\n",
    "    print(connections)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1affbce9-b94b-4e0c-a91d-0f88769d4983'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_id = response.json()[0]['id']\n",
    "db_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '370262d3-5cbb-4bcf-bdb0-ac8f08e44b74',\n",
       "  'db_connection_id': '1affbce9-b94b-4e0c-a91d-0f88769d4983',\n",
       "  'db_schema': 'public',\n",
       "  'table_name': 'service_instances',\n",
       "  'columns': [],\n",
       "  'examples': [],\n",
       "  'table_description': None,\n",
       "  'table_embedding': None,\n",
       "  'table_schema': None,\n",
       "  'sync_status': 'NOT_SCANNED',\n",
       "  'last_sync': None,\n",
       "  'error_message': None,\n",
       "  'metadata': None,\n",
       "  'created_at': '2024-09-10T22:10:26.843621'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/api/v1/table-descriptions\"\n",
    "params = {}\n",
    "params['db_connection_id'] = db_id\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "print(response.status_code)\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'370262d3-5cbb-4bcf-bdb0-ac8f08e44b74'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_id = response.json()[0]['id']\n",
    "table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error: 500, Traceback (most recent call last):\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\fastapi\\routing.py\", line 297, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\concurrency.py\", line 39, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\Documents\\GitHub\\KAI\\app\\api\\__init__.py\", line 439, in refresh_table_description\n    table_descriptions = self.table_description_service.refresh_table_description(\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\Documents\\GitHub\\KAI\\app\\modules\\table_description\\services\\__init__.py\", line 73, in refresh_table_description\n    database_connection_service = DatabaseConnectionService(self.storage)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: DatabaseConnectionService.__init__() missing 1 required positional argument: 'storage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrefresh_table_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[25], line 15\u001b[0m, in \u001b[0;36mrefresh_table_descriptions\u001b[1;34m(db_connection_id)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()  \u001b[38;5;66;03m# or handle the response as needed\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Error: 500, Traceback (most recent call last):\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 735, in app\n    await route.handle(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 62, in wrapped_app\n    raise exc\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 51, in wrapped_app\n    await app(scope, receive, sender)\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\fastapi\\routing.py\", line 297, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\starlette\\concurrency.py\", line 39, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func, *args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\anaconda3\\envs\\KAI-dev\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\Documents\\GitHub\\KAI\\app\\api\\__init__.py\", line 439, in refresh_table_description\n    table_descriptions = self.table_description_service.refresh_table_description(\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edisu\\Documents\\GitHub\\KAI\\app\\modules\\table_description\\services\\__init__.py\", line 73, in refresh_table_description\n    database_connection_service = DatabaseConnectionService(self.storage)\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: DatabaseConnectionService.__init__() missing 1 required positional argument: 'storage'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def refresh_table_descriptions(db_connection_id):\n",
    "    url = \"http://localhost:8000/api/v1/table-descriptions/refresh\"\n",
    "    params = {}\n",
    "    params['database_connection_id'] = db_connection_id\n",
    "    \n",
    "    # Send a POST request\n",
    "    response = requests.post(url, params=params)\n",
    "\n",
    "    # Check the response status and return accordingly\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # or handle the response as needed\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "# Example usage\n",
    "result = refresh_table_descriptions(db_id)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 201\n",
      "Response JSON: [{'id': '370262d3-5cbb-4bcf-bdb0-ac8f08e44b74', 'db_connection_id': '1affbce9-b94b-4e0c-a91d-0f88769d4983', 'db_schema': 'public', 'table_name': 'service_instances', 'columns': [], 'examples': [], 'table_description': None, 'table_embedding': None, 'table_schema': None, 'sync_status': 'SYNCHRONIZING', 'last_sync': None, 'error_message': None, 'metadata': {}, 'created_at': '2024-09-11T10:04:31.907107'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define your request body\n",
    "request_body = {\n",
    "    \"table_description_ids\": [table_id],\n",
    "    \"metadata\": {}\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(\"http://localhost:8000/api/v1/table-descriptions/sync-schemas\", json=request_body)\n",
    "\n",
    "# Print the response\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response JSON:\", response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '76639ffb-e6b1-4ab6-96b5-e1fcc3a3dba4',\n",
       " 'metadata': {},\n",
       " 'created_at': '2024-09-11T11:48:20.380818',\n",
       " 'text': 'What is the average revenue loss due to churn in 2023?',\n",
       " 'db_connection_id': '1affbce9-b94b-4e0c-a91d-0f88769d4983',\n",
       " 'schemas': ['public']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define your request body for creating a prompt\n",
    "request_body = {\n",
    "    \"text\": \"What is the average revenue loss due to churn in 2023?\",   # Replace with the actual prompt text\n",
    "    \"db_connection_id\": db_id,  # Replace with your actual DB connection ID\n",
    "    \"schemas\": [\"public\"],  # Add your actual schemas\n",
    "    \"context\": [{}],  # Replace with actual context objects if needed\n",
    "    \"metadata\": {}    # Add any additional metadata if needed\n",
    "}\n",
    "\n",
    "# Send the POST request to create a prompt\n",
    "response = requests.post(\"http://localhost:8000/api/v1/prompts\", json=request_body)\n",
    "\n",
    "# Print the response\n",
    "print(\"Status Code:\", response.status_code)\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76639ffb-e6b1-4ab6-96b5-e1fcc3a3dba4'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_id = response.json()['id']\n",
    "prompt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Generation Status Code: 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '578b5b86-0f24-4316-90bb-9859bffe35ca',\n",
       " 'metadata': None,\n",
       " 'created_at': '2024-09-11T11:48:52.240555',\n",
       " 'prompt_id': '76639ffb-e6b1-4ab6-96b5-e1fcc3a3dba4',\n",
       " 'status': 'VALID',\n",
       " 'llm_config': {'llm_name': 'gpt-4o-mini', 'api_base': None},\n",
       " 'intermediate_steps': [{'thought': 'I should find the relevant tables.\\n',\n",
       "   'action': 'DbTablesWithRelevanceScores',\n",
       "   'action_input': 'What is the average revenue loss due to churn in 2023?',\n",
       "   'observation': 'Table: `public.service_instances`, relevance score: 0.68\\n'},\n",
       "  {'thought': 'I need to check the schema of the `public.service_instances` table to identify the relevant columns for calculating the average revenue loss due to churn in 2023.  \\n',\n",
       "   'action': 'DbRelevantTablesSchema',\n",
       "   'action_input': 'public.service_instances',\n",
       "   'observation': '```sql\\n\\nCREATE TABLE service_instances (\\n\\tservice_instance_id VARCHAR(50), \\n\\tservice_instance_region VARCHAR(50), \\n\\tservice_instance_area VARCHAR(50), \\n\\tservice_instance_cluster VARCHAR(50), \\n\\tcustomer_id INTEGER, \\n\\tcustomer_name VARCHAR(50), \\n\\tcustomer_category VARCHAR(50), \\n\\tcustomer_sub_category VARCHAR(50), \\n\\tproduct_name VARCHAR(50), \\n\\tproduct_category_level1 VARCHAR(50), \\n\\tproduct_category_level2 VARCHAR(50), \\n\\tproduct_category_level3 VARCHAR(50), \\n\\tproduct_category_level4 VARCHAR(50), \\n\\tcontract_start_date VARCHAR(50), \\n\\tcontract_end_date VARCHAR(50), \\n\\tis_contract_automated_rollover INTEGER, \\n\\tsla_total_due_customer INTEGER, \\n\\tsla_total_due_system INTEGER, \\n\\tsla_mttr_due_customer INTEGER, \\n\\tsla_mttr_due_system INTEGER, \\n\\tsla_performance INTEGER, \\n\\tsla_availability INTEGER, \\n\\ttickets_non_technical_sum INTEGER, \\n\\ttickets_technical_sum INTEGER, \\n\\ttickets_mttr INTEGER, \\n\\ttickets_open_duration INTEGER, \\n\\ttickets_age INTEGER, \\n\\tpoi_atm_count INTEGER, \\n\\tpoi_sustenance_count INTEGER, \\n\\tpoi_transportation_count INTEGER, \\n\\tpoi_healthcare_count INTEGER, \\n\\ttenure_months INTEGER, \\n\\thas_churned INTEGER, \\n\\tchurn_propensity_score REAL, \\n\\tchurn_prediction_category VARCHAR(50), \\n\\tprimary_churn_driver VARCHAR(50), \\n\\trecommended_business_action VARCHAR(64), \\n\\trevenue_lost_due_churn INTEGER, \\n\\tis_contract_end INTEGER, \\n\\tservice_instance_revenue INTEGER, \\n\\tdate_timestamp VARCHAR(50),\\n\\t);\\n```\\n'},\n",
       "  {'thought': 'I have the schema of the `public.service_instances` table, which includes the `revenue_lost_due_churn` column that will help in calculating the average revenue loss due to churn. I also need to filter the records for the year 2023 based on the `date_timestamp` column.\\n\\nNext, I will check the values in the `date_timestamp` column to ensure it contains valid date entries for filtering.  \\n',\n",
       "   'action': 'DbRelevantColumnsInfo',\n",
       "   'action_input': 'public.service_instances -> date_timestamp',\n",
       "   'observation': \"Table: \\nCREATE TABLE service_instances (\\n\\tservice_instance_id VARCHAR(50), \\n\\tservice_instance_region VARCHAR(50), \\n\\tservice_instance_area VARCHAR(50), \\n\\tservice_instance_cluster VARCHAR(50), \\n\\tcustomer_id INTEGER, \\n\\tcustomer_name VARCHAR(50), \\n\\tcustomer_category VARCHAR(50), \\n\\tcustomer_sub_category VARCHAR(50), \\n\\tproduct_name VARCHAR(50), \\n\\tproduct_category_level1 VARCHAR(50), \\n\\tproduct_category_level2 VARCHAR(50), \\n\\tproduct_category_level3 VARCHAR(50), \\n\\tproduct_category_level4 VARCHAR(50), \\n\\tcontract_start_date VARCHAR(50), \\n\\tcontract_end_date VARCHAR(50), \\n\\tis_contract_automated_rollover INTEGER, \\n\\tsla_total_due_customer INTEGER, \\n\\tsla_total_due_system INTEGER, \\n\\tsla_mttr_due_customer INTEGER, \\n\\tsla_mttr_due_system INTEGER, \\n\\tsla_performance INTEGER, \\n\\tsla_availability INTEGER, \\n\\ttickets_non_technical_sum INTEGER, \\n\\ttickets_technical_sum INTEGER, \\n\\ttickets_mttr INTEGER, \\n\\ttickets_open_duration INTEGER, \\n\\ttickets_age INTEGER, \\n\\tpoi_atm_count INTEGER, \\n\\tpoi_sustenance_count INTEGER, \\n\\tpoi_transportation_count INTEGER, \\n\\tpoi_healthcare_count INTEGER, \\n\\ttenure_months INTEGER, \\n\\thas_churned INTEGER, \\n\\tchurn_propensity_score REAL, \\n\\tchurn_prediction_category VARCHAR(50), \\n\\tprimary_churn_driver VARCHAR(50), \\n\\trecommended_business_action VARCHAR(64), \\n\\trevenue_lost_due_churn INTEGER, \\n\\tis_contract_end INTEGER, \\n\\tservice_instance_revenue INTEGER, \\n\\tdate_timestamp VARCHAR(50),\\n\\t);.service_instances, column: date_timestamp, additional info: Description: None, categories = ['2024-05-08', '2024-06-07', '2024-07-07'], Sample rows: 2024-05-08, 2024-05-08, 2024-05-08\\n\"},\n",
       "  {'thought': \"The `date_timestamp` column contains values that are not from the year 2023, which means I need to check for the correct date format and ensure that I can filter for the year 2023. Since the column is of type `VARCHAR`, I will need to ensure that the values can be interpreted as dates.\\n\\nNext, I will construct the SQL query to calculate the average revenue loss due to churn in 2023, filtering out any records that do not belong to that year. \\n\\nHere is the SQL query I will use:\\n\\n```sql\\n-- Calculate the average revenue loss due to churn in 2023\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss\\nFROM public.service_instances\\nWHERE \\n    -- Filter for records where the date is in 2023\\n    date_timestamp >= '2023-01-01' AND date_timestamp < '2024-01-01'\\n    AND revenue_lost_due_churn IS NOT NULL; -- Exclude NULL values\\n```\\n\\nNow, I will execute this query to ensure it is correct.  \\n\",\n",
       "   'action': 'SqlDbQuery',\n",
       "   'action_input': \"```sql\\n-- Calculate the average revenue loss due to churn in 2023\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss\\nFROM public.service_instances\\nWHERE \\n    -- Filter for records where the date is in 2023\\n    date_timestamp >= '2023-01-01' AND date_timestamp < '2024-01-01'\\n    AND revenue_lost_due_churn IS NOT NULL; -- Exclude NULL values\\n```\",\n",
       "   'observation': 'QUERY RESULTS ARE NOT STORED FOR PRIVACY REASONS.'},\n",
       "  {'thought': \"The query returned `None` for the average revenue loss, which indicates that there may not be any records in the `public.service_instances` table for the year 2023, or the filtering conditions are not capturing any relevant data. \\n\\nTo further investigate, I will check if there are any records in the `date_timestamp` column that fall within the year 2023. This will help confirm whether the absence of data is the issue. \\n\\nI will construct a query to count the number of records for the year 2023:\\n\\n```sql\\n-- Count the number of records for the year 2023\\nSELECT COUNT(*) AS record_count\\nFROM public.service_instances\\nWHERE \\n    -- Filter for records where the date is in 2023\\n    date_timestamp >= '2023-01-01' AND date_timestamp < '2024-01-01';\\n```\\n\\nNow, I will execute this query to check the number of records for 2023.  \\n\",\n",
       "   'action': 'SqlDbQuery',\n",
       "   'action_input': \"```sql\\n-- Count the number of records for the year 2023\\nSELECT COUNT(*) AS record_count\\nFROM public.service_instances\\nWHERE \\n    -- Filter for records where the date is in 2023\\n    date_timestamp >= '2023-01-01' AND date_timestamp < '2024-01-01';\\n```\",\n",
       "   'observation': 'QUERY RESULTS ARE NOT STORED FOR PRIVACY REASONS.'}],\n",
       " 'sql': \"-- Count the number of records for the year 2023\\nSELECT COUNT(*) AS record_count\\nFROM public.service_instances\\nWHERE \\n    -- Filter for records where the date is in 2023\\n    date_timestamp >= '2023-01-01' AND date_timestamp < '2024-01-01';\",\n",
       " 'tokens_used': 12200,\n",
       " 'confidence_score': None,\n",
       " 'completed_at': '2024-09-11 11:49:23.619595',\n",
       " 'error': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Create the request body for SQL generation\n",
    "sql_generation_request_body = {\n",
    "    \"llm_config\": {\n",
    "        \"llm_name\": \"gpt-4o-mini\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# prompt_id = \"dc354596-6aad-45fe-92e5-1af57ac42609\"\n",
    "# Send the POST request to create SQL generation\n",
    "sql_generation_response = requests.post(\n",
    "    f\"http://localhost:8000/api/v1/prompts/{prompt_id}/sql-generations\", \n",
    "    json=sql_generation_request_body\n",
    ")\n",
    "\n",
    "# # Print the response from the SQL generation request\n",
    "print(\"SQL Generation Status Code:\", sql_generation_response.status_code)\n",
    "sql_generation_response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_generation_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Generation Status Code: 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '8abfc1e8-a03f-44da-8546-a36a8dc319d9',\n",
       " 'metadata': None,\n",
       " 'created_at': '2024-09-11T13:03:26.746225',\n",
       " 'prompt_id': '18700bc6-aa64-489b-aaed-122cb5066d47',\n",
       " 'status': 'VALID',\n",
       " 'llm_config': {'llm_name': 'gpt-4o-mini', 'api_base': None},\n",
       " 'intermediate_steps': [{'thought': 'I should find the relevant tables.\\n',\n",
       "   'action': 'DbTablesWithRelevanceScores',\n",
       "   'action_input': 'What is the average revenue loss due to churn in 2024?',\n",
       "   'observation': 'Table: `public.service_instances`, relevance score: 0.6774\\n'},\n",
       "  {'thought': 'I need to get the schema of the relevant table `public.service_instances` to identify the columns that might contain information about revenue and churn.  \\n',\n",
       "   'action': 'DbRelevantTablesSchema',\n",
       "   'action_input': 'public.service_instances',\n",
       "   'observation': '```sql\\n\\nCREATE TABLE service_instances (\\n\\tservice_instance_id VARCHAR(50), \\n\\tservice_instance_region VARCHAR(50), \\n\\tservice_instance_area VARCHAR(50), \\n\\tservice_instance_cluster VARCHAR(50), \\n\\tcustomer_id INTEGER, \\n\\tcustomer_name VARCHAR(50), \\n\\tcustomer_category VARCHAR(50), \\n\\tcustomer_sub_category VARCHAR(50), \\n\\tproduct_name VARCHAR(50), \\n\\tproduct_category_level1 VARCHAR(50), \\n\\tproduct_category_level2 VARCHAR(50), \\n\\tproduct_category_level3 VARCHAR(50), \\n\\tproduct_category_level4 VARCHAR(50), \\n\\tcontract_start_date VARCHAR(50), \\n\\tcontract_end_date VARCHAR(50), \\n\\tis_contract_automated_rollover INTEGER, \\n\\tsla_total_due_customer INTEGER, \\n\\tsla_total_due_system INTEGER, \\n\\tsla_mttr_due_customer INTEGER, \\n\\tsla_mttr_due_system INTEGER, \\n\\tsla_performance INTEGER, \\n\\tsla_availability INTEGER, \\n\\ttickets_non_technical_sum INTEGER, \\n\\ttickets_technical_sum INTEGER, \\n\\ttickets_mttr INTEGER, \\n\\ttickets_open_duration INTEGER, \\n\\ttickets_age INTEGER, \\n\\tpoi_atm_count INTEGER, \\n\\tpoi_sustenance_count INTEGER, \\n\\tpoi_transportation_count INTEGER, \\n\\tpoi_healthcare_count INTEGER, \\n\\ttenure_months INTEGER, \\n\\thas_churned INTEGER, \\n\\tchurn_propensity_score REAL, \\n\\tchurn_prediction_category VARCHAR(50), \\n\\tprimary_churn_driver VARCHAR(50), \\n\\trecommended_business_action VARCHAR(64), \\n\\trevenue_lost_due_churn INTEGER, \\n\\tis_contract_end INTEGER, \\n\\tservice_instance_revenue INTEGER, \\n\\tdate_timestamp VARCHAR(50),\\n\\t);\\n```\\n'},\n",
       "  {'thought': 'I have the schema for the `public.service_instances` table, which includes the `revenue_lost_due_churn` column that likely contains the revenue loss due to churn. I also see a `date_timestamp` column that can be used to filter records for the year 2024. \\n\\nNext, I will check the values in the `date_timestamp` column to ensure it contains relevant date information for filtering. \\n\\n',\n",
       "   'action': 'DbRelevantColumnsInfo',\n",
       "   'action_input': 'public.service_instances -> date_timestamp',\n",
       "   'observation': \"Table: \\nCREATE TABLE service_instances (\\n\\tservice_instance_id VARCHAR(50), \\n\\tservice_instance_region VARCHAR(50), \\n\\tservice_instance_area VARCHAR(50), \\n\\tservice_instance_cluster VARCHAR(50), \\n\\tcustomer_id INTEGER, \\n\\tcustomer_name VARCHAR(50), \\n\\tcustomer_category VARCHAR(50), \\n\\tcustomer_sub_category VARCHAR(50), \\n\\tproduct_name VARCHAR(50), \\n\\tproduct_category_level1 VARCHAR(50), \\n\\tproduct_category_level2 VARCHAR(50), \\n\\tproduct_category_level3 VARCHAR(50), \\n\\tproduct_category_level4 VARCHAR(50), \\n\\tcontract_start_date VARCHAR(50), \\n\\tcontract_end_date VARCHAR(50), \\n\\tis_contract_automated_rollover INTEGER, \\n\\tsla_total_due_customer INTEGER, \\n\\tsla_total_due_system INTEGER, \\n\\tsla_mttr_due_customer INTEGER, \\n\\tsla_mttr_due_system INTEGER, \\n\\tsla_performance INTEGER, \\n\\tsla_availability INTEGER, \\n\\ttickets_non_technical_sum INTEGER, \\n\\ttickets_technical_sum INTEGER, \\n\\ttickets_mttr INTEGER, \\n\\ttickets_open_duration INTEGER, \\n\\ttickets_age INTEGER, \\n\\tpoi_atm_count INTEGER, \\n\\tpoi_sustenance_count INTEGER, \\n\\tpoi_transportation_count INTEGER, \\n\\tpoi_healthcare_count INTEGER, \\n\\ttenure_months INTEGER, \\n\\thas_churned INTEGER, \\n\\tchurn_propensity_score REAL, \\n\\tchurn_prediction_category VARCHAR(50), \\n\\tprimary_churn_driver VARCHAR(50), \\n\\trecommended_business_action VARCHAR(64), \\n\\trevenue_lost_due_churn INTEGER, \\n\\tis_contract_end INTEGER, \\n\\tservice_instance_revenue INTEGER, \\n\\tdate_timestamp VARCHAR(50),\\n\\t);.service_instances, column: date_timestamp, additional info: Description: None, categories = ['2024-05-08', '2024-06-07', '2024-07-07'], Sample rows: 2024-05-08, 2024-05-08, 2024-05-08\\n\"},\n",
       "  {'thought': \"The `date_timestamp` column contains relevant date information for the year 2024. Now, I can construct a SQL query to calculate the average revenue loss due to churn for that year. \\n\\nThe SQL query will:\\n1. Filter records where the `date_timestamp` is in the year 2024.\\n2. Calculate the average of the `revenue_lost_due_churn` column for those filtered records.\\n\\nHere is the SQL query I will use:\\n\\n```sql\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss_due_to_churn -- Calculate the average revenue loss due to churn\\nFROM public.service_instances -- From the service_instances table\\nWHERE date_timestamp LIKE '2024%' -- Filter for records in the year 2024\\nAND revenue_lost_due_churn IS NOT NULL; -- Exclude records with NULL revenue loss\\n```\\n\\nNow, I will execute this SQL query to ensure it is correct. \\n\\n\",\n",
       "   'action': 'SqlDbQuery',\n",
       "   'action_input': \"```sql\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss_due_to_churn -- Calculate the average revenue loss due to churn\\nFROM public.service_instances -- From the service_instances table\\nWHERE date_timestamp LIKE '2024%' -- Filter for records in the year 2024\\nAND revenue_lost_due_churn IS NOT NULL; -- Exclude records with NULL revenue loss\\n```\",\n",
       "   'observation': 'QUERY RESULTS ARE NOT STORED FOR PRIVACY REASONS.'}],\n",
       " 'sql': \"SELECT AVG(revenue_lost_due_churn) AS average_revenue_loss_due_to_churn -- Calculate the average revenue loss due to churn\\nFROM public.service_instances -- From the service_instances table\\nWHERE date_timestamp LIKE '2024%' -- Filter for records in the year 2024\\nAND revenue_lost_due_churn IS NOT NULL; -- Exclude records with NULL revenue loss\",\n",
       " 'tokens_used': 9136,\n",
       " 'confidence_score': None,\n",
       " 'completed_at': '2024-09-11 13:03:36.895666',\n",
       " 'error': None}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define your request body for creating a prompt\n",
    "request_body = {\n",
    "    \"text\": \"What is the average revenue loss due to churn in 2024?\",   # Replace with the actual prompt text\n",
    "    \"db_connection_id\": db_id,  # Replace with your actual DB connection ID\n",
    "    \"schemas\": [\"public\"],  # Add your actual schemas\n",
    "    \"context\": [{}],  # Replace with actual context objects if needed\n",
    "    \"metadata\": {}    # Add any additional metadata if needed\n",
    "}\n",
    "\n",
    "# Send the POST request to create a prompt\n",
    "response = requests.post(\"http://localhost:8000/api/v1/prompts\", json=request_body)\n",
    "prompt_id = response.json()['id']\n",
    "\n",
    "sql_generation_response = requests.post(\n",
    "    f\"http://localhost:8000/api/v1/prompts/{prompt_id}/sql-generations\", \n",
    "    json=sql_generation_request_body\n",
    ")\n",
    "\n",
    "# # Print the response from the SQL generation request\n",
    "print(\"SQL Generation Status Code:\", sql_generation_response.status_code)\n",
    "sql_generation_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_generation_id = sql_generation_response.json()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL Generation Status Code: 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ae27b30c-621a-47ba-8ca6-430fa86cad6d',\n",
       " 'metadata': {},\n",
       " 'created_at': '2024-09-11 13:09:23.400168',\n",
       " 'sql_generation_id': '8abfc1e8-a03f-44da-8546-a36a8dc319d9',\n",
       " 'llm_config': {'llm_name': 'gpt-4o-mini', 'api_base': None},\n",
       " 'text': 'The average revenue loss due to churn in 2024 is approximately 203,993,975.47.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_generation_request_body = {\n",
    "    \"llm_config\": {\n",
    "        \"llm_name\": \"gpt-4o-mini\"\n",
    "    },\n",
    "    \"max_rows\": 100,\n",
    "    \"metadata\": {}\n",
    "\n",
    "}\n",
    "\n",
    "nl_generation_response = requests.post(\n",
    "    f\"http://localhost:8000/api/v1/sql-generations/{sql_generation_id}/nl-generations\", \n",
    "    json=nl_generation_request_body\n",
    ")\n",
    "\n",
    "print(\"NL Generation Status Code:\", nl_generation_response.status_code)\n",
    "nl_generation_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions Status Code: 201\n",
      "Instructions Response: {'id': 'df1d1201-996f-40c9-8892-5e7848d2b3ad', 'metadata': {}, 'created_at': '2024-09-11T13:14:12.742501', 'db_connection_id': '1affbce9-b94b-4e0c-a91d-0f88769d4983', 'condition': 'if no year is specified', 'rules': 'query 2024 data', 'is_default': True}\n"
     ]
    }
   ],
   "source": [
    "# Prepare the request body\n",
    "instructions_request_body = {\n",
    "    \"db_connection_id\": db_id,  # Replace with your database connection ID\n",
    "    \"condition\": \"if no year is specified\",                  # Replace with the condition you want to specify\n",
    "    \"rules\": \"query 2024 data\",                          # Replace with your rules\n",
    "    \"is_default\": True,\n",
    "    \"metadata\": {}\n",
    "}\n",
    "\n",
    "# Make the POST request to create instructions\n",
    "instructions_response = requests.post(\n",
    "    \"http://localhost:8000/api/v1/instructions\", \n",
    "    json=instructions_request_body\n",
    ")\n",
    "\n",
    "# Print the status code and response\n",
    "print(\"Instructions Status Code:\", instructions_response.status_code)\n",
    "print(\"Instructions Response:\", instructions_response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL Generation Status Code: 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'bbc3baf4-66af-4318-8492-1492193b600c',\n",
       " 'metadata': {},\n",
       " 'created_at': '2024-09-11 13:19:14.879176',\n",
       " 'sql_generation_id': 'f2591d95-7313-47d8-b6a8-2e4da6f6c8ec',\n",
       " 'llm_config': {'llm_name': 'gpt-4o-mini', 'api_base': None},\n",
       " 'text': 'The average revenue loss due to churn is approximately 203,993,975.47.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_name = \"gpt-4o-mini\"\n",
    "# Prepare the request body for NL generations\n",
    "nl_generation_request_body = {\n",
    "    \"llm_config\": {\n",
    "        \"llm_name\": llm_name,\n",
    "    },\n",
    "    \"max_rows\": 100,\n",
    "    \"metadata\": {},\n",
    "    \"sql_generation\": {\n",
    "        \"llm_config\": {\n",
    "            \"llm_name\": llm_name,\n",
    "        },\n",
    "        \"evaluate\": False,\n",
    "        \"metadata\": {},\n",
    "        \"prompt\": {\n",
    "            \"text\": \"What is the average revenue loss due to churn?\",  # Replace with your actual prompt\n",
    "            \"db_connection_id\": db_id,  # Use the same db_connection_id as earlier\n",
    "            \"schemas\": [\"public\"],  # Replace with relevant schema(s)\n",
    "            \"context\": [{}],  # You can add relevant context if needed\n",
    "            \"metadata\": {}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make the POST request to create NL generations\n",
    "nl_generation_response = requests.post(\n",
    "    \"http://localhost:8000/api/v1/prompts/sql-generations/nl-generations\",\n",
    "    json=nl_generation_request_body\n",
    ")\n",
    "\n",
    "# Print the status code and response\n",
    "print(\"NL Generation Status Code:\", nl_generation_response.status_code)\n",
    "nl_generation_response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f2591d95-7313-47d8-b6a8-2e4da6f6c8ec'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_id_to_store = nl_generation_response.json()['sql_generation_id']\n",
    "sql_id_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Generation Status Code: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'f2591d95-7313-47d8-b6a8-2e4da6f6c8ec',\n",
       " 'metadata': {},\n",
       " 'created_at': '2024-09-11T13:19:04.057385',\n",
       " 'prompt_id': 'd56e52a7-0a4e-4e97-ac17-4cf1e749bd58',\n",
       " 'status': 'VALID',\n",
       " 'llm_config': {'llm_name': 'gpt-4o-mini', 'api_base': None},\n",
       " 'intermediate_steps': [{'thought': 'I should find the relevant tables.\\n',\n",
       "   'action': 'DbTablesWithRelevanceScores',\n",
       "   'action_input': 'What is the average revenue loss due to churn?',\n",
       "   'observation': 'Table: `public.service_instances`, relevance score: 0.695\\n'},\n",
       "  {'thought': 'I need to retrieve the schema of the relevant table `public.service_instances` to identify the columns that might contain information about revenue and churn.  \\n',\n",
       "   'action': 'DbRelevantTablesSchema',\n",
       "   'action_input': 'public.service_instances',\n",
       "   'observation': '```sql\\n\\nCREATE TABLE service_instances (\\n\\tservice_instance_id VARCHAR(50), \\n\\tservice_instance_region VARCHAR(50), \\n\\tservice_instance_area VARCHAR(50), \\n\\tservice_instance_cluster VARCHAR(50), \\n\\tcustomer_id INTEGER, \\n\\tcustomer_name VARCHAR(50), \\n\\tcustomer_category VARCHAR(50), \\n\\tcustomer_sub_category VARCHAR(50), \\n\\tproduct_name VARCHAR(50), \\n\\tproduct_category_level1 VARCHAR(50), \\n\\tproduct_category_level2 VARCHAR(50), \\n\\tproduct_category_level3 VARCHAR(50), \\n\\tproduct_category_level4 VARCHAR(50), \\n\\tcontract_start_date VARCHAR(50), \\n\\tcontract_end_date VARCHAR(50), \\n\\tis_contract_automated_rollover INTEGER, \\n\\tsla_total_due_customer INTEGER, \\n\\tsla_total_due_system INTEGER, \\n\\tsla_mttr_due_customer INTEGER, \\n\\tsla_mttr_due_system INTEGER, \\n\\tsla_performance INTEGER, \\n\\tsla_availability INTEGER, \\n\\ttickets_non_technical_sum INTEGER, \\n\\ttickets_technical_sum INTEGER, \\n\\ttickets_mttr INTEGER, \\n\\ttickets_open_duration INTEGER, \\n\\ttickets_age INTEGER, \\n\\tpoi_atm_count INTEGER, \\n\\tpoi_sustenance_count INTEGER, \\n\\tpoi_transportation_count INTEGER, \\n\\tpoi_healthcare_count INTEGER, \\n\\ttenure_months INTEGER, \\n\\thas_churned INTEGER, \\n\\tchurn_propensity_score REAL, \\n\\tchurn_prediction_category VARCHAR(50), \\n\\tprimary_churn_driver VARCHAR(50), \\n\\trecommended_business_action VARCHAR(64), \\n\\trevenue_lost_due_churn INTEGER, \\n\\tis_contract_end INTEGER, \\n\\tservice_instance_revenue INTEGER, \\n\\tdate_timestamp VARCHAR(50),\\n\\t);\\n```\\n'},\n",
       "  {'thought': 'I have the schema for the `public.service_instances` table, which includes the `revenue_lost_due_churn` and `service_instance_revenue` columns. I will now check if there are any NULL values in the `revenue_lost_due_churn` column to ensure accurate calculations. \\n\\n',\n",
       "   'action': 'DbRelevantColumnsInfo',\n",
       "   'action_input': 'public.service_instances -> revenue_lost_due_churn',\n",
       "   'observation': 'Table: \\nCREATE TABLE service_instances (\\n\\tservice_instance_id VARCHAR(50), \\n\\tservice_instance_region VARCHAR(50), \\n\\tservice_instance_area VARCHAR(50), \\n\\tservice_instance_cluster VARCHAR(50), \\n\\tcustomer_id INTEGER, \\n\\tcustomer_name VARCHAR(50), \\n\\tcustomer_category VARCHAR(50), \\n\\tcustomer_sub_category VARCHAR(50), \\n\\tproduct_name VARCHAR(50), \\n\\tproduct_category_level1 VARCHAR(50), \\n\\tproduct_category_level2 VARCHAR(50), \\n\\tproduct_category_level3 VARCHAR(50), \\n\\tproduct_category_level4 VARCHAR(50), \\n\\tcontract_start_date VARCHAR(50), \\n\\tcontract_end_date VARCHAR(50), \\n\\tis_contract_automated_rollover INTEGER, \\n\\tsla_total_due_customer INTEGER, \\n\\tsla_total_due_system INTEGER, \\n\\tsla_mttr_due_customer INTEGER, \\n\\tsla_mttr_due_system INTEGER, \\n\\tsla_performance INTEGER, \\n\\tsla_availability INTEGER, \\n\\ttickets_non_technical_sum INTEGER, \\n\\ttickets_technical_sum INTEGER, \\n\\ttickets_mttr INTEGER, \\n\\ttickets_open_duration INTEGER, \\n\\ttickets_age INTEGER, \\n\\tpoi_atm_count INTEGER, \\n\\tpoi_sustenance_count INTEGER, \\n\\tpoi_transportation_count INTEGER, \\n\\tpoi_healthcare_count INTEGER, \\n\\ttenure_months INTEGER, \\n\\thas_churned INTEGER, \\n\\tchurn_propensity_score REAL, \\n\\tchurn_prediction_category VARCHAR(50), \\n\\tprimary_churn_driver VARCHAR(50), \\n\\trecommended_business_action VARCHAR(64), \\n\\trevenue_lost_due_churn INTEGER, \\n\\tis_contract_end INTEGER, \\n\\tservice_instance_revenue INTEGER, \\n\\tdate_timestamp VARCHAR(50),\\n\\t);.service_instances, column: revenue_lost_due_churn, additional info: Description: None, Sample rows: 36000000, 468000000, 408000000\\n'},\n",
       "  {'thought': 'The `revenue_lost_due_churn` column does not contain NULL values based on the sample rows provided. Now, I will proceed to calculate the average revenue loss due to churn using the `revenue_lost_due_churn` column from the `public.service_instances` table.\\n\\n',\n",
       "   'action': 'GetAdminInstructions',\n",
       "   'action_input': '',\n",
       "   'observation': 'Admin: All of the generated SQL queries must follow the below instructions:\\n1) if no year is specified, query 2024 data\\n'},\n",
       "  {'thought': \"I need to write a SQL query to calculate the average revenue loss due to churn from the `revenue_lost_due_churn` column in the `public.service_instances` table, ensuring that I follow the admin instructions to query data for the year 2024.\\n\\nHere is the SQL query I will construct:\\n\\n```sql\\n-- Calculate the average revenue loss due to churn for the year 2024\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss_due_to_churn\\nFROM public.service_instances\\nWHERE date_timestamp >= '2024-01-01' AND date_timestamp < '2025-01-01'; -- Filter for the year 2024\\n```\\n\\nNow, I will execute this SQL query to ensure it is correct. \\n\\n\",\n",
       "   'action': 'SqlDbQuery',\n",
       "   'action_input': \"```sql\\n-- Calculate the average revenue loss due to churn for the year 2024\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss_due_to_churn\\nFROM public.service_instances\\nWHERE date_timestamp >= '2024-01-01' AND date_timestamp < '2025-01-01'; -- Filter for the year 2024\\n```\",\n",
       "   'observation': 'QUERY RESULTS ARE NOT STORED FOR PRIVACY REASONS.'}],\n",
       " 'sql': \"-- Calculate the average revenue loss due to churn for the year 2024\\nSELECT AVG(revenue_lost_due_churn) AS average_revenue_loss_due_to_churn\\nFROM public.service_instances\\nWHERE date_timestamp >= '2024-01-01' AND date_timestamp < '2025-01-01'; -- Filter for the year 2024\",\n",
       " 'tokens_used': 11625,\n",
       " 'confidence_score': None,\n",
       " 'completed_at': '2024-09-11 13:19:14.789997',\n",
       " 'error': None}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace with your actual sql_generation_id\n",
    "sql_generation_id = sql_id_to_store\n",
    "\n",
    "# Make the GET request to retrieve SQL generations\n",
    "sql_generation_response = requests.get(\n",
    "    f\"http://localhost:8000/api/v1/sql-generations/{sql_generation_id}\"\n",
    ")\n",
    "\n",
    "# Print the status code and response\n",
    "print(\"SQL Generation Status Code:\", sql_generation_response.status_code)\n",
    "prompt_id_to_store = sql_generation_response.json()['prompt_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAI-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
